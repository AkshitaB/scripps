{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The required format for the GLAD program is:\n",
    "```\n",
    "First line:\n",
    "    <numGivenLabels> <numLabelers> <numTasks> <Prior p(Z=1)>\n",
    "  Following <numGivenLabels> lines:\n",
    "    <taskId> <labelerId> <label:0|1>\n",
    "```\n",
    "0: Not a Disease (Includes \"Phenotype\")\n",
    "<br>\n",
    "1: Disease (Includes \"Both\")\n",
    "\n",
    "I think task refers to the word in the dataset, and then labeler ID and the label. So if we have 20000 words in M2C and 5 label, the output of this program should have 100000 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = 'dataset/Mark2Cure_citizen_phenotype/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "citizens = ['1', '2', '3', '4', '5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'M2C{}-Disease_Phen_Preliminary_Run_1st_pass.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make vocab\n",
    "vocab = {}\n",
    "reverse_vocab = {}\n",
    "count_vocab = dict()\n",
    "path = dataset_folder + filename.format('1')\n",
    "i = 0\n",
    "total_lines = 0\n",
    "with open(path) as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            total_lines += 1\n",
    "            word = line.split()[0]\n",
    "            word = word.lower()\n",
    "            c = count_vocab.get(word, 0)\n",
    "            count_vocab[word] = c + 1\n",
    "            word = word + '_{}'.format(i)\n",
    "            if word.lower() not in vocab:\n",
    "                vocab[word.lower()] = i\n",
    "                reverse_vocab[i] = word.lower()\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7863, 2245)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab), len(count_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 5 arrays of text\n",
    "annotations = []\n",
    "for citizen in citizens:\n",
    "    path = dataset_folder + filename.format(citizen)\n",
    "    with open(path) as f:\n",
    "        lines = f.read().split('\\n')\n",
    "        annotations.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '{} {} {} {} {} {}\\n'.format(len(vocab)*len(annotations), len(annotations), len(vocab), 2, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7864, 7863)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations), total_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = dict()\n",
    "for line in range(total_lines):\n",
    "    for annotator in range(len(annotations)):\n",
    "        current_line = annotations[annotator][line].split()\n",
    "        word = current_line[0].lower() + '_{}'.format(line)\n",
    "        annotation = current_line[3]\n",
    "        count = record.get(word, 0)\n",
    "        if count < len(annotations):\n",
    "            label = '1'\n",
    "            if annotation == 'O':\n",
    "                label = '0'\n",
    "            text = text + '{} {} {}\\n'.format(vocab[word], annotator, label)\n",
    "            record[word] = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_phenotype_wordidx.txt', 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following code is to convert the alpha, beta and label csv to readable formats AFTER we run GLAD\n",
    "\n",
    "### Make sure you have the proper files in the proper folder before running these hacky snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = 'Results for word_idx/'\n",
    "files = ['beta.csv', 'label.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_betas = {}\n",
    "text = ''\n",
    "with open(results_folder+'beta.csv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            arr = line.split(',')\n",
    "            num = arr[0]\n",
    "            if num == '# id':\n",
    "                continue\n",
    "            word = reverse_vocab[int(num)-1].split('_')[0]\n",
    "            beta_temp = dict_betas.get(word, 0.0)\n",
    "            dict_betas[word] = beta_temp + float(arr[1])\n",
    "for word, _ in dict_betas.items():\n",
    "    text += '{}\\t{}\\n'.format(word, dict_betas[word]/count_vocab[word])\n",
    "with open(results_folder+'beta_word_idx.csv','w') as g:\n",
    "    g.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "p_0 = {}\n",
    "p_1 = {}\n",
    "with open(results_folder+'label.csv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            arr = line.split(',')\n",
    "            num = arr[0]\n",
    "            if num == '# id':\n",
    "                continue\n",
    "            word = reverse_vocab[int(num)-1].split('_')[0]\n",
    "            \n",
    "            p_0_value = p_0.get(word, 0.0)\n",
    "            p_0[word] = p_0_value + float(arr[1])\n",
    "            \n",
    "            p_1_value = p_1.get(word, 0.0)\n",
    "            p_1[word] = p_1_value + float(arr[2])\n",
    "            \n",
    "for word, _ in p_0.items():\n",
    "    text += '{}\\t{}\\t{}\\n'.format(word, p_0[word]/count_vocab[word], p_1[word]/count_vocab[word])\n",
    "    \n",
    "with open(results_folder+'label_word_idx.csv','w') as g:\n",
    "    g.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
