{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The required format for the GLAD program is:\n",
    "```\n",
    "First line:\n",
    "    <numGivenLabels> <numLabelers> <numTasks> <Prior p(Z=1)>\n",
    "  Following <numGivenLabels> lines:\n",
    "    <taskId> <labelerId> <label:0|1>\n",
    "```\n",
    "0: Not a Disease (Includes \"Phenotype\")\n",
    "<br>\n",
    "1: Disease (Includes \"Both\")\n",
    "\n",
    "I think task refers to the word in the dataset, and then labeler ID and the label. So if we have 20000 words in M2C and 5 label, the output of this program should have 100000 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = 'dataset/Mark2Cure_citizen_phenotype/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "citizens = ['1', '2', '3', '4', '5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'M2C{}-Disease_Phen_Preliminary_Run_1st_pass.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make vocab\n",
    "vocab = {}\n",
    "reverse_vocab = {}\n",
    "sentences, labels = [], []\n",
    "count_vocab = dict()\n",
    "path = dataset_folder + filename.format('1')\n",
    "i = 0\n",
    "total_lines = 0\n",
    "with open(path) as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    sent_temp, labels_temp = [], []\n",
    "    for line in range(len(lines)):\n",
    "        try:\n",
    "            word = lines[line].split()[0].lower()\n",
    "            if word == '.':\n",
    "                labels.append(labels_temp)\n",
    "                sent_temp, labels_temp = [], []\n",
    "            elif word not in '.,:-+=_\\\\|/<>()!@#$%^&*':\n",
    "                labels_temp.append(lines[line].split()[-1])\n",
    "                c = count_vocab.get(word, 0)\n",
    "                count_vocab[word] = c + 1\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = i\n",
    "                    reverse_vocab[i] = word\n",
    "                    i += 1\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2234"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make bigram vocab:\n",
    "## Make vocab\n",
    "bigram_vocab = {}\n",
    "reverse_bigram_vocab = {}\n",
    "path = dataset_folder + filename.format('1')\n",
    "i = 0\n",
    "\n",
    "\n",
    "def make_bigrams(path):\n",
    "    all_lines = ['<pad>']\n",
    "    all_labels = ['O']\n",
    "    bigram_lines = []\n",
    "    bigram_labels = []\n",
    "    i = 0\n",
    "    wordidx = 0\n",
    "    with open(path) as f:\n",
    "        lines = f.read().split('\\n')\n",
    "        for line in lines:\n",
    "            if line == '':\n",
    "                continue\n",
    "            label = line.split()[-1]\n",
    "            line = line.split()[0].lower()\n",
    "            if line not in ',:-+=_\\\\|/<>()!@#$%^&*':\n",
    "                all_lines.append(line+'_{}'.format(wordidx))\n",
    "                wordidx += 1\n",
    "                all_labels.append(label)\n",
    "                if line == '.':\n",
    "                    all_lines.append('<pad>')\n",
    "                    all_labels.append('O')\n",
    "\n",
    "    flag = False #because we need <pad> before beginning the sentence\n",
    "    for idx in range(len(all_lines) - 1):\n",
    "        if all_lines[idx].split('_')[0] == '.':\n",
    "            continue\n",
    "        elif all_lines[idx+1].split('_')[0] == '.':\n",
    "            continue\n",
    "\n",
    "        bigram = (all_lines[idx], all_lines[idx+1])\n",
    "        bigram_label = all_labels[idx+1]\n",
    "\n",
    "        if bigram not in bigram_vocab:\n",
    "            bigram_vocab[bigram] = i\n",
    "            reverse_bigram_vocab[i] = bigram\n",
    "            i += 1\n",
    "\n",
    "        bigram_lines.append(bigram)\n",
    "        bigram_labels.append(bigram_label)\n",
    "    return bigram_lines, bigram_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 5 arrays of text\n",
    "anno_bigrams, anno_labels = [], []\n",
    "for citizen in citizens:\n",
    "    path = dataset_folder + filename.format(citizen)\n",
    "    bigrams, labels = make_bigrams(path)\n",
    "    anno_bigrams.append(bigrams)\n",
    "    anno_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '{} {} {} {} {} {}\\n'.format(len(bigram_vocab)*len(anno_bigrams), len(anno_bigrams), len(bigram_vocab), 2, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bigram in range(len(anno_bigrams[0])):\n",
    "    for annotator in range(len(anno_bigrams)):\n",
    "        label = '1'\n",
    "        if anno_labels[annotator][bigram] == 'O':\n",
    "            label = '0'\n",
    "        text = text + '{} {} {}\\n'.format(bigram_vocab[anno_bigrams[annotator][bigram]], annotator, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_phenotype_bigrams.txt', 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following code is to convert the alpha, beta and label csv to readable formats AFTER we run GLAD\n",
    "\n",
    "### Make sure you have the proper files in the proper folder before running these hacky snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = 'Results for bigram/'\n",
    "files = ['beta.csv', 'label.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_betas = {}\n",
    "text += '{}\\t{}\\n'.format('Word', 'Difficulty')\n",
    "with open(results_folder+'beta.csv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            arr = line.split(',')\n",
    "            num = arr[0]\n",
    "            if num == '# id':\n",
    "                continue\n",
    "            word = reverse_bigram_vocab[int(num)-1][1].split('_')[0]\n",
    "            beta_temp = dict_betas.get(word, 0.0)\n",
    "            dict_betas[word] = beta_temp + float(arr[1])\n",
    "for word, _ in dict_betas.items():\n",
    "    text += '{}\\t{}\\n'.format(word, dict_betas[word]/count_vocab[word])\n",
    "with open(results_folder+'beta_bigram.csv','w') as g:\n",
    "    g.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '{}\\t{}\\t{}\\n'.format('Word', 'P(None)', 'P(Phenotype)')\n",
    "p_0 = {}\n",
    "p_1 = {}\n",
    "with open(results_folder+'label.csv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            arr = line.split(',')\n",
    "            num = arr[0]\n",
    "            if num == '# id':\n",
    "                continue\n",
    "            word = reverse_bigram_vocab[int(num)-1][1].split('_')[0]\n",
    "            \n",
    "            p_0_value = p_0.get(word, 0.0)\n",
    "            p_0[word] = p_0_value + float(arr[1])\n",
    "            \n",
    "            p_1_value = p_1.get(word, 0.0)\n",
    "            p_1[word] = p_1_value + float(arr[2])\n",
    "            \n",
    "for word, _ in p_0.items():\n",
    "    text += '{}\\t{}\\t{}\\n'.format(word, p_0[word]/count_vocab[word], p_1[word]/count_vocab[word])\n",
    "    \n",
    "with open(results_folder+'label_bigram.csv','w') as g:\n",
    "    g.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
