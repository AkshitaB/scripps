{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The required format for the GLAD program is:\n",
    "```\n",
    "First line:\n",
    "    <numGivenLabels> <numLabelers> <numTasks> <Prior p(Z=1)>\n",
    "  Following <numGivenLabels> lines:\n",
    "    <taskId> <labelerId> <label:0|1>\n",
    "```\n",
    "0: Not a Disease (Includes \"Phenotype\")\n",
    "<br>\n",
    "1: Disease (Includes \"Both\")\n",
    "\n",
    "I think task refers to the word in the dataset, and then labeler ID and the label. So if we have 20000 words in M2C and 5 label, the output of this program should have 100000 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = 'dataset/Mark2Cure_citizen_phenotype/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "citizens = ['1', '2', '3', '4', '5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'M2C{}-Disease_Phen_Preliminary_Run_1st_pass.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make vocab\n",
    "vocab = {}\n",
    "reverse_vocab = {}\n",
    "sentences, labels = [], []\n",
    "count_vocab = dict()\n",
    "path = dataset_folder + filename.format('1')\n",
    "i = 0\n",
    "total_lines = 0\n",
    "with open(path) as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    sent_temp, labels_temp = [], []\n",
    "    for line in range(len(lines)):\n",
    "        try:\n",
    "            word = lines[line].split()[0].lower()\n",
    "            if word == '.':\n",
    "                labels.append(labels_temp)\n",
    "                sent_temp, labels_temp = [], []\n",
    "            elif word not in '.,:-+=_\\\\|/<>()!@#$%^&*':\n",
    "                labels_temp.append(lines[line].split()[-1])\n",
    "                c = count_vocab.get(word, 0)\n",
    "                count_vocab[word] = c + 1\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = i\n",
    "                    reverse_vocab[i] = word\n",
    "                    i += 1\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2234"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make trigram vocab:\n",
    "## Make vocab\n",
    "trigram_vocab = {}\n",
    "reverse_trigram_vocab = {}\n",
    "path = dataset_folder + filename.format('1')\n",
    "i = 0\n",
    "\n",
    "\n",
    "def make_trigrams(path):\n",
    "    all_lines = ['<pad>']\n",
    "    all_labels = ['O']\n",
    "    trigram_lines = []\n",
    "    trigram_labels = []\n",
    "    i = 0\n",
    "    wordidx = 0\n",
    "    with open(path) as f:\n",
    "        lines = f.read().split('\\n')\n",
    "        for line in lines:\n",
    "            if line == '':\n",
    "                continue\n",
    "            label = line.split()[-1]\n",
    "            line = line.split()[0].lower()\n",
    "            if line not in ',:-+=_\\\\|/<>()!@#$%^&*':\n",
    "                all_lines.append(line+'_{}'.format(wordidx))\n",
    "                wordidx += 1\n",
    "                all_labels.append(label)\n",
    "                if line == '.':\n",
    "                    all_lines.append('<pad>')\n",
    "                    all_labels.append('O')\n",
    "\n",
    "    flag = False #because we need <pad> before beginning the sentence\n",
    "    for idx in range(len(all_lines) - 2):\n",
    "        if all_lines[idx].split('_')[0] == '.':\n",
    "            continue\n",
    "        elif all_lines[idx+1].split('_')[0] == '.':\n",
    "            continue\n",
    "        elif all_lines[idx+2].split('_')[0] == '.':\n",
    "            continue\n",
    "\n",
    "        trigram = (all_lines[idx], all_lines[idx+1], all_lines[idx+2])\n",
    "        trigram_label = all_labels[idx+1]\n",
    "\n",
    "        if trigram not in trigram_vocab:\n",
    "            trigram_vocab[trigram] = i\n",
    "            reverse_trigram_vocab[i] = trigram\n",
    "            i += 1\n",
    "\n",
    "        trigram_lines.append(trigram)\n",
    "        trigram_labels.append(trigram_label)\n",
    "    return trigram_lines, trigram_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 5 arrays of text\n",
    "anno_trigrams, anno_labels = [], []\n",
    "for citizen in citizens:\n",
    "    path = dataset_folder + filename.format(citizen)\n",
    "    trigrams, labels = make_trigrams(path)\n",
    "    anno_trigrams.append(trigrams)\n",
    "    anno_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '{} {} {} {} {} {}\\n'.format(len(trigram_vocab)*len(anno_trigrams), len(anno_trigrams), len(trigram_vocab), 2, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trigram in range(len(anno_trigrams[0])):\n",
    "    for annotator in range(len(anno_trigrams)):\n",
    "        label = '1'\n",
    "        if anno_labels[annotator][trigram] == 'O':\n",
    "            label = '0'\n",
    "        text = text + '{} {} {}\\n'.format(trigram_vocab[anno_trigrams[annotator][trigram]], annotator, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_phenotype_trigrams.txt', 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following code is to convert the alpha, beta and label csv to readable formats AFTER we run GLAD\n",
    "\n",
    "### Make sure you have the proper files in the proper folder before running these hacky snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = 'Results/Results for trigram/'\n",
    "files = ['beta.csv', 'label.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_betas = {}\n",
    "text = '{}\\t{}\\n'.format('Word', 'Difficulty')\n",
    "with open(results_folder+'beta.csv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            arr = line.split(',')\n",
    "            num = arr[0]\n",
    "            if num == '# id':\n",
    "                continue\n",
    "            word = reverse_trigram_vocab[int(num)-1][1].split('_')[0]\n",
    "            beta_temp = dict_betas.get(word, 0.0)\n",
    "            dict_betas[word] = beta_temp + float(arr[1])\n",
    "for word, _ in dict_betas.items():\n",
    "    text += '{}\\t{}\\n'.format(word, dict_betas[word]/count_vocab[word])\n",
    "with open(results_folder+'beta_trigram.csv','w') as g:\n",
    "    g.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '{}\\t{}\\t{}\\n'.format('Word', 'P(None)', 'P(Phenotype)')\n",
    "p_0 = {}\n",
    "p_1 = {}\n",
    "with open(results_folder+'label.csv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            arr = line.split(',')\n",
    "            num = arr[0]\n",
    "            if num == '# id':\n",
    "                continue\n",
    "            word = reverse_trigram_vocab[int(num)-1][1].split('_')[0]\n",
    "            \n",
    "            p_0_value = p_0.get(word, 0.0)\n",
    "            p_0[word] = p_0_value + float(arr[1])\n",
    "            \n",
    "            p_1_value = p_1.get(word, 0.0)\n",
    "            p_1[word] = p_1_value + float(arr[2])\n",
    "            \n",
    "for word, _ in p_0.items():\n",
    "    text += '{}\\t{}\\t{}\\n'.format(word, p_0[word]/count_vocab[word], p_1[word]/count_vocab[word])\n",
    "    \n",
    "with open(results_folder+'label_trigram.csv','w') as g:\n",
    "    g.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
