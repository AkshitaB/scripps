#!/bin/bash

# Set up CoNLL-2003 train/test/dev data
#export name_suffix="CoNLL_random_2"
#export name_suffix="CoNLL_to"
export name_suffix="CoNLL"
#export name_suffix="CoNLL_h_topic_to"
export data_name="conll2003"
#export data_name_show="WMT"
export data_name_show="NCBI_disease"
#export raw_data_dir="$DATA_DIR/conll2003/random_2"
#export raw_data_dir="$DATA_DIR/NCBI_disease"
export raw_data_dir="$DATA_DIR/"

export source_subset_size="30000"
#export source_subset_size=$subset_size
#export data_files=( "eng.train" "eng.testa" "eng.testb" )
#export data_files=( "eng.train_first_${name_suffix}_$subset_size" )
#export data_files=( "eng.active_cv_test_${name_suffix}_30000" )
#export created_single_file="eng.train_CoNLL_random_2_unique_30000"
#export created_single_file="eng.train_CoNLL_random_2_unique_30000-100000"
#export created_single_file="WMT/news.2011.en_${name_suffix}_tra_rest_$source_subset_size"

#export created_single_file="NCBI_disease/pubtator_first_500000-550000.txt"
export created_single_file="NCBI_disease_random/pubtator_${name_suffix}_tra_rest_$source_subset_size"


export data_files=( "$created_single_file" )
# todo get this number automagically
export max_sent_len=126
export process_script="$DILATED_CNN_NER_ROOT/src/tsv_to_tfrecords.py"

#export training_file_name="WMT/news.2011.en_${name_suffix}_train_$subset_size"

#export training_file_name="NCBItrainset_corpus_CoNLL.txt"
export training_file_name="NCBI_disease_random/pubtator_CoNLL_train_$source_subset_size"

#export data_dir="$processed_data_dir/$data_name_show-w$filter_width-$embeddings_name-CoNLL_to-inc-US-$source_subset_size"
#export data_dir="$processed_data_dir/$data_name_show-w$filter_width-$embeddings_name-$name_suffix"
export data_dir="$processed_data_dir/$data_name_show-w$filter_width-$embeddings_name-$name_suffix-$source_subset_size"

#export data_dir="$processed_data_dir/$data_name_show-w$filter_width-$embeddings_name-${name_suffix}_train-$source_subset_size"
#export name_suffix="CoNLL_to"
#export from_subset_size="30000"
#export selection_method="error_w_10_sent_100_topic_len_shape_0_WMT_scale_f"
#export training_file_name="WMT/to_${subset_size}/eng.train_first_${name_suffix}_${from_subset_size}-${subset_size}_$selection_method"
#export data_dir="$processed_data_dir/$data_name_show-w$filter_width-$embeddings_name-$training_file_name"

if [[ "$start_end" == "true" ]]; then
    export data_dir="$data_dir-start_end"
fi

if [[ "$predict_pad" == "true" ]]; then
    export data_dir="$data_dir-pred_pad"
fi

if [[ "$documents" == "true" ]]; then
    export data_dir="$data_dir-docs"
fi

#export train_dir="$data_dir/eng.train_${name_suffix}_$source_subset_size"
#export dev_dir="$data_dir/$created_single_file"
#export train_rest_dir="$data_dir/active_cv_test_${name_suffix}_30000"
#export train_dir="$data_dir/WMT/news.2011.en_${name_suffix}_train_$subset_size"
export train_dir="$data_dir/$training_file_name"
export train_rest_dir=$data_dir/$created_single_file
#export maps_dir=$data_dir/eng.train_${name_suffix}_$source_subset_size
export maps_dir="$train_dir"

#export vocab_cutoff=4
#export update_vocab_file="$DILATED_CNN_NER_ROOT/data/vocabs/${data_name}_cutoff_${vocab_cutoff}_${name_suffix}_$subset_size.txt"



