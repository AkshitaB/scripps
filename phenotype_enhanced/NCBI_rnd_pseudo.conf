#!/bin/bash

# Set up CoNLL-2003 train/test/dev data
#export name_suffix="CoNLL_random_2_to"
#export name_suffix="CoNLL_to"
export name_suffix="CoNLL"
#export name_suffix="CoNLL_h_topic_to"
export data_name="conll2003"
#export data_name_show="WMT"
export data_name_show="NCBI_disease"
export run_version="one"
export US_method="random"
export raw_data_dir="$DATA_DIR"
#export data_files=( "eng.train" "eng.testa" "eng.testb" )
#eng.train_US_first_CoNLL_to_35000_all_rest
#eng.tra_US_rest_CoNLL_to_35000_all_rest
#pubtator_CoNLL_train_first_30000
#export data_files=( "WMT/news.2011.en_${name_suffix}_train_${subset_size}" "WMT/news.2011.en_${name_suffix}_tra_rest_${subset_size}" "basic/eng.testa" "basic/eng.testb" )
export data_files=( "${data_name_show}_random/pubtator_CoNLL_train_first_$subset_size" "${data_name_show}_random/pubtator_CoNLL_tra_rest_$subset_size" "${data_name_show}/NCBIdevelopset_corpus_d_CoNLL.txt" "${data_name_show}/NCBItestset_corpus_d_CoNLL.txt")
#export data_files=( "WMT/to_$subset_size/eng.train_US_first_${name_suffix}_${subset_size}_all_rest" "conll2003/basic/eng.testa" "conll2003/basic/eng.testb" )
# todo get this number automagically
export max_sent_len=126
export process_script="$DILATED_CNN_NER_ROOT/src/tsv_to_tfrecords.py"

#export data_dir="$processed_data_dir/$data_name-w$filter_width-$embeddings_name-$name_suffix-inc-error_uncertain_topic_length-$subset_size"
#export data_dir="$processed_data_dir/$data_name_show-w$filter_width-$embeddings_name-$name_suffix-$subset_size"
export data_dir="$processed_data_dir/$data_name_show-w$filter_width-$embeddings_name-${name_suffix}-${run_version}-pseudo-$subset_size"

if [[ "$start_end" == "true" ]]; then
    export data_dir="$data_dir-start_end"
fi

if [[ "$predict_pad" == "true" ]]; then
    export data_dir="$data_dir-pred_pad"
fi

if [[ "$documents" == "true" ]]; then
    export data_dir="$data_dir-docs"
fi

#export train_dir="$data_dir/eng.train_first_${name_suffix}_$subset_size"
#export train_rest_dir="$data_dir/eng.tra_rest_${name_suffix}_$subset_size"
#export train_dir="$data_dir/eng.train_US_first_${name_suffix}_$subset_size"
export train_dir="$data_dir/${data_files[0]}"
echo $train_dir
export train_rest_dir="$data_dir/${data_files[1]}"
export dev_dir="$data_dir/${data_files[2]}"
export test_dir="$data_dir/${data_files[3]}"
#export train_rest_dir="$data_dir/${data_files[3]}"
#export test_2_dir="$data_dir/${data_files[3]}"

export maps_dir=$train_dir

export vocab_cutoff=4
export update_vocab_file="$DILATED_CNN_NER_ROOT/data/vocabs/${data_name_show}_cutoff_${vocab_cutoff}_${name_suffix}_pseudo_${subset_size}.txt"

